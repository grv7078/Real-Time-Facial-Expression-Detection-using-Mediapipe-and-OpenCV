{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c729e9d5-f6a7-43ba-8a90-84fcb384eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe FaceMesh and Drawing Utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def calculate_distance(point1, point2):\n",
    "    return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "# Function to analyze facial expressions\n",
    "def analyze_expression(landmarks, width, height):\n",
    "    # Extract key points for expression detection\n",
    "    left_eye_inner = landmarks[133]  # Inner corner of left eye\n",
    "    right_eye_inner = landmarks[362]  # Inner corner of right eye\n",
    "    mouth_left = landmarks[61]  # Left corner of mouth\n",
    "    mouth_right = landmarks[291]  # Right corner of mouth\n",
    "    upper_lip = landmarks[13]  # Upper lip center\n",
    "    lower_lip = landmarks[14]  # Lower lip center\n",
    "\n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    def denormalize(point):\n",
    "        return int(point.x * width), int(point.y * height)\n",
    "\n",
    "    left_eye = denormalize(left_eye_inner)\n",
    "    right_eye = denormalize(right_eye_inner)\n",
    "    mouth_left = denormalize(mouth_left)\n",
    "    mouth_right = denormalize(mouth_right)\n",
    "    upper_lip = denormalize(upper_lip)\n",
    "    lower_lip = denormalize(lower_lip)\n",
    "\n",
    "    # Calculate distances\n",
    "    eye_distance = calculate_distance(left_eye, right_eye)\n",
    "    mouth_width = calculate_distance(mouth_left, mouth_right)\n",
    "    mouth_height = calculate_distance(upper_lip, lower_lip)\n",
    "\n",
    "    # Detect expressions based on distances\n",
    "    if mouth_height / mouth_width > 0.5:\n",
    "        return \"Surprised\"\n",
    "    elif mouth_width / eye_distance > 1.8:\n",
    "        return \"Smiling\"\n",
    "    elif mouth_height / mouth_width < 0.15 and mouth_width / eye_distance < 1.5:\n",
    "        return \"Neutral\"\n",
    "    #elif mouth_height / mouth_width < 0.2 and eye_distance / mouth_width < 1.2:\n",
    "        #return \"Angry\"\n",
    "    else:\n",
    "        return \"Angry\"\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Initialize FaceMesh\n",
    "    with mp_face_mesh.FaceMesh(\n",
    "        static_image_mode=False,\n",
    "        max_num_faces=1,\n",
    "        refine_landmarks=True,\n",
    "        min_detection_confidence=0.5,\n",
    "        min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame.\")\n",
    "                break\n",
    "\n",
    "            height, width, _ = frame.shape\n",
    "\n",
    "            # Convert the frame to RGB as Mediapipe works with RGB images\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Process the frame with FaceMesh\n",
    "            results = face_mesh.process(rgb_frame)\n",
    "\n",
    "            # Prepare a blank canvas for plotting points\n",
    "            blank_canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "            expression = \"Neutral\"\n",
    "\n",
    "            # Draw face landmarks and analyze expression if detected\n",
    "            if results.multi_face_landmarks:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    # Draw landmarks\n",
    "                    mp_drawing.draw_landmarks(\n",
    "                        image=frame,\n",
    "                        landmark_list=face_landmarks,\n",
    "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None,\n",
    "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "\n",
    "                    # Extract landmark points\n",
    "                    landmarks = face_landmarks.landmark\n",
    "\n",
    "                    # Detect and display expression\n",
    "                    expression = analyze_expression(landmarks, width, height)\n",
    "\n",
    "                    # Highlight key points on the blank canvas\n",
    "                    for lm in landmarks:\n",
    "                        x, y = int(lm.x * width), int(lm.y * height)\n",
    "                        cv2.circle(blank_canvas, (x, y), 2, (0, 255, 0), -1)\n",
    "\n",
    "            # Combine both windows into one composite image\n",
    "            composite = np.hstack((frame, blank_canvas))\n",
    "\n",
    "            # Display expression on the combined window\n",
    "            cv2.putText(composite, f\"Expression: {expression}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Show the composite image\n",
    "            cv2.imshow('Face Mesh and Plotted Points', composite)\n",
    "\n",
    "            # Exit on pressing 'Q' or 'ESC'\n",
    "            key = cv2.waitKey(1)\n",
    "            if key & 0xFF == ord('q') or key & 0xFF == 27:\n",
    "                break\n",
    "\n",
    "    # Release resources\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98414367-6c1f-49c7-bd41-02aed215140e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047f53f-43af-4e00-9ea1-fdb0a6abf127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
